{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd044051-b8c7-46d2-9de7-cf580c401aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "#imorting os and sys to add the path of different site_package\\dir to jupyter notebook\n",
    "import os\n",
    "import sys\n",
    "directory_path = os.path.abspath(os.path.join('F:\\LLM-project\\cuda\\Lib\\site-packages'))\n",
    "if directory_path not in sys.path:\n",
    "    sys.path.append(directory_path)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import mmap\n",
    "import random\n",
    "import pickle\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92bc7080-f4de-4b60-9418-868f5efbed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -batch_size BATCH_SIZE\n",
      "ipykernel_launcher.py: error: the following arguments are required: -batch_size\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhib\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='This is a demonstration program')\n",
    "parser.add_argument('-batch_size', type=str, required=True, help='Please provide an llms')\n",
    "args=parser.parse_args()\n",
    "print(f'-batch_size:{args.batch_size}')\n",
    "#block_size is the numbre of blocks/list in the stacks\n",
    "#batch_size is the number of values int the tensor\n",
    "batch_size=args.batch_size\n",
    "block_size=128\n",
    "max_iters=200\n",
    "#eval_interval=2500\n",
    "learning_rate=3e-4\n",
    "eval_iters=20\n",
    "dropout=0.2\n",
    "n_embd=384 \n",
    "n_layer=1\n",
    "n_head=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0479128c-13ac-48a4-bf79-371590c29374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this checks if gpu is available or not for fast computation\n",
    "#as cpu performs task in sequential manner which is time consuming for training and testing purposes\n",
    "#gpu is used to run more than task parrallely\n",
    "device ='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "072a3248-22d8-4457-8dc3-591f246ced66",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=\"\"\n",
    "with open('open_corpus/vocab.txt','r',encoding='utf-8') as f:\n",
    "    text=f.read()\n",
    "    chars=sorted(list(set(text)))\n",
    "vocab_size=len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "506d91a7-db6d-44f5-916d-a9ac9a5217db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding and decoding\n",
    "#mapping from string to int\n",
    "# string_to_int is a dictionnary which is mode of key value pair of char and its index in the chars set\n",
    "string_to_int={ch:i for i,ch in enumerate(chars)}\n",
    "\n",
    "#mapping from int to string \n",
    "# int_to_String is a dictionnary which is mode of key value pair of index and its value in the chars set\n",
    "int_to_string={i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "#encode is a list  function which input a string and output a list off indexs of the characters in the string \n",
    "encode=lambda s:[string_to_int[c] for c in s]\n",
    "\n",
    "#lambda function takes a list of integers l as input and returns a string by decoding each integer in the input list using the int_to_string dictionary.\n",
    "decode=lambda l:''.join([int_to_string[i] for i in l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f9dd594-42d6-4292-8903-badf077d63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensors are  multi-dimensional arrays or generalizations of matrices that can have any number of dimensions. \n",
    "#data is list(tensor) which stores the character in encoded form\n",
    "#data = torch.tensor(encode(text), dtype=torch.long)\n",
    "#print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dcb0b14-b05c-4c71-92ff-d8f55f42e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are dividing the data into training and validation dataset \n",
    "#n is represnting 80% of the len data\n",
    "# here we are dividing training:validating in 80:20 ratio\n",
    "# n=int(0.8*len(data))\n",
    "#train_data=data[:n]\n",
    "#val_data=data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78eb6be2-629c-4d2c-95a4-a80c766b63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory map for using small snippets of text from a single file of any size \n",
    "def random_chunk(split):\n",
    "    filename=\"open_corpus/output_train.txt\" if split =='train' else \"open_corpus/output_val.txt\"\n",
    "    with open(filename,'rb') as f:\n",
    "        with mmap.mmap(f.fileno(),0,access=mmap.ACCESS_READ) as mm:\n",
    "\n",
    "            #detemine the file size and a random positoin to start reading\n",
    "            file_size=len(mm)\n",
    "            start_pos=random.randint(0,(file_size)-block_size*batch_size)\n",
    "            #seek ti the random position vand read the block of text\n",
    "            mm.seek(start_pos)\n",
    "            block=mm.read(block_size*batch_size-1)\n",
    "            decoded_block=block.decode('utf-8',errors='ignore').replace('\\r','')\n",
    "            #train and test splits\n",
    "            data=torch.tensor(encode(decoded_block),dtype=torch.long)\n",
    "    return data\n",
    "#get_batch is used select a specific data from the dataset \n",
    "def get_batch(split):\n",
    "    \n",
    "    #data is the the tensor on which we are working on \n",
    "    #we initially divided the dataset into 80:20 into train vs test\n",
    "    data=random_chunk(split)\n",
    "    \n",
    "    #ix is list of random integers of length batch_size from starting to data-block_size\n",
    "    ix=torch.randint(len(data)-block_size,(batch_size,))\n",
    "    \n",
    "    #x is the stack of training dataset of length 8\n",
    "    x=torch.stack([data[i:i+block_size] for i in ix])\n",
    "    \n",
    "    #y is the same stack with one offset for predicting values\n",
    "    y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    \n",
    "    #x,y shift to gpu(Cuda) if it is available\n",
    "    x,y=x.to(device), y.to(device)\n",
    "    \n",
    "    #print(device)\n",
    "    #returning pair of stack x and y\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "897871fe-6be8-4c3f-9b57-1e9756d4ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss estimation \n",
    "# This decorator is used before defining the estimate_loss function. \n",
    "#It temporarily disables gradient tracking for all the operations inside the function.\n",
    "@torch.no_grad()\n",
    "\n",
    "def estimate_loss():\n",
    "    #out is initialized as an empty dictionary. It will be used to store the estimated losses for the training and validation datasets.\n",
    "    out={}\n",
    "    # sets the model into evaluation mode.\n",
    "    # In evaluation mode, the model behaves differently from training mode, typically disabling features like dropout and batch normalization.\n",
    "    model.eval()\n",
    "    \n",
    "    for split in ['train','val']: # estimate the loss separately for both the training and validation datasets.\n",
    "        \n",
    "        losses =torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X,Y = get_batch(split)\n",
    "\n",
    "            # (model) is used to compute predictions (logits) and calculate the loss (loss) between the predictions and the target data.\n",
    "            logits,loss=model(X,Y)\n",
    "\n",
    "            #This keeps track of the loss for each iteration.\n",
    "            losses[k]=loss.item()\n",
    "\n",
    "        # calculates the mean (average) of the losses obtained during those iterations. \n",
    "        out[split]=losses.mean()\n",
    "    model.train()\n",
    "\n",
    "    #estimated losses for both the training and validation datasets.\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8e49fbb-04e4-4ad3-98b9-2330ab1d1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single head of self-attention used in multi-head attention mechanisms within transformer models\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # Key represents the information you want to compare against or use as a reference\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "\n",
    "        # Query is the information that you are currently processing or seeking to understand better\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "\n",
    "        # Value is the information associated with the query which provides additional context\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "\n",
    "        # Buffer contains a lower triangular matrix with ones below the main diagonal and zeros above it.\n",
    "        # This matrix is used for masking during attention computations.\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # B, T, and C represent the batch size, sequence length, and input dimension\n",
    "        B, T, C = x.shape\n",
    "        \n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "\n",
    "        # The attention mechanism computes the attention weights using the dot product between query and key vectors,\n",
    "        # which is scaled by a factor of k.shape[-1]**-0.5 (the square root of the key dimension).\n",
    "        wei = q @ k.transpose(-2, -1) * (k.shape[-1] ** -0.5)\n",
    "\n",
    "        # This masking ensures that the model doesn't attend to future elements in the sequence\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "\n",
    "        # Normalize them and obtain valid attention probabilities\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        \n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "        \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multiple heads of self-attention in parallel\"\"\"\n",
    "    \n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # num_heads represents the number of attention heads to use in parallel.\n",
    "        # head_size is the number of features captured by each attention head.\n",
    "\n",
    "        # A container for multiple attention heads.\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "\n",
    "        # self.proj is a linear projection layer used to combine the outputs of the individual attention heads.\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Outputs of the attention heads are concatenated along the last dimension\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\"A simple layer followed by non-linearity\"\"\"\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "\n",
    "        # A container for defining a sequence of operations in PyTorch.\n",
    "        self.net = nn.Sequential(\n",
    "            # Takes an input of dimension n_embd and produces an intermediate output with a dimension that is four times the input dimension\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Reduces the dimensionality back to the original input dimension\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "\n",
    "            # The dropout layer is used for regularization\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        # Head size is the number of features that each head will be capturing in our multi-head attention\n",
    "        head_size = n_embd // n_head\n",
    "\n",
    "        # Self-attention \n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "\n",
    "        # The feedforward layer is responsible for capturing complex patterns and features in the data.\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "\n",
    "        # Layer normalization helps stabilize training by normalizing the activations within each layer.\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x\n",
    "        \n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # This line creates an embedding layer for token embeddings.\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "\n",
    "        # This line creates an embedding layer for positional embeddings.\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "\n",
    "        # This line defines a sequence of neural network blocks.\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "\n",
    "        # This line defines a layer normalization operation. \n",
    "        # Layer normalization is used to stabilize and normalize the activations between layers in a neural network.\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "\n",
    "        # This line defines a linear (fully connected) layer for language modeling.\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "\n",
    "        B,T=index.shape\n",
    "        # idx and targets are both (B, T) tensors of integers\n",
    "        tok_emb = self.token_embedding_table(index) \n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
    "\n",
    "        # This line combines the token embeddings and positional embeddings by element-wise addition\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # .shape is used to unpack the items of logits into B, T, C\n",
    "            # B is for batch, T is for time, C is for the number of classes\n",
    "            B, T, C = logits.shape            \n",
    "            # .view is used to pack them alternate of .shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            \n",
    "            # This function computes the loss between the predicted logits (logits) and the ground truth labels (targets).\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "    # Purpose of the generate function: generate a sequence of tokens or indices given an initial context (index)\n",
    "    # and a maximum number of new tokens (max_new_tokens).\n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        # Create a new tensor for the generated sequence\n",
    "        generated_sequence = index\n",
    "    \n",
    "        for _ in range(max_new_tokens):\n",
    "            # Get the predictions\n",
    "            logits, loss = self.forward(generated_sequence)\n",
    "            \n",
    "            # Focus only on the last time step\n",
    "            logits = logits[:, -1, :]\n",
    "            \n",
    "            # Focus only on the last time step\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Sample from the distribution\n",
    "            num_samples = 1\n",
    "            index_next = torch.multinomial(probs, num_samples)\n",
    "    \n",
    "            # Append sampled index to the running sequence\n",
    "            generated_sequence = torch.cat((generated_sequence, index_next), dim=1)\n",
    "    \n",
    "        return generated_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb58dcea-e164-46e2-9189-5e287c4918ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model parameters..\n",
      "loaded succes\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of GPTLanguageModel named \"model\"\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "\n",
    "print('loading model parameters..')\n",
    "with open('model-01.pkl','rb') as f:\n",
    "    model=pickle.load(f)\n",
    "print('loaded succes')\n",
    "# Move the model to GPU if available\n",
    "m = model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4d33342-d2cf-4953-900a-ad7d25e7369d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28miter\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m eval_iters \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Sample a batch of data\u001b[39;00m\n",
      "File \u001b[1;32mF:\\LLM-project\\cuda\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 20\u001b[0m, in \u001b[0;36mestimate_loss\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m X,Y \u001b[38;5;241m=\u001b[39m get_batch(split)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# (model) is used to compute predictions (logits) and calculate the loss (loss) between the predictions and the target data.\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m logits,loss\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#This keeps track of the loss for each iteration.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m losses[k]\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mF:\\LLM-project\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[23], line 163\u001b[0m, in \u001b[0;36mGPTLanguageModel.forward\u001b[1;34m(self, index, targets)\u001b[0m\n\u001b[0;32m    160\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mview(B \u001b[38;5;241m*\u001b[39m T)\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# This function computes the loss between the predicted logits (logits) and the ground truth labels (targets).\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits, loss\n",
      "File \u001b[1;32mF:\\LLM-project\\cuda\\Lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "for iter in range(max_iters):\n",
    "    print(iter)\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step:{iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "    # Sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # Evaluate the loss\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "\n",
    "    # This line clears (zeros out) the gradients of the model's parameters.\n",
    "    # Gradients accumulate during each backward pass, so this step ensures that the gradients start fresh for the current batch.\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    # This line computes the gradients of the loss with respect to the model's parameters.\n",
    "    # These gradients are computed to understand how the loss changes as the parameters are adjusted.\n",
    "    loss.backward()\n",
    "\n",
    "    \n",
    "    # This line updates the model's parameters based on the computed gradients and the learning rate (lr).\n",
    "    # It effectively performs a parameter update step to minimize the loss.\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n",
    "with open('model-01.pkl','wb')as f:\n",
    "    pickle.dump(model,f)\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7be5e-cd09-4400-b1f8-90156ce6cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
